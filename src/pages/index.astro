---
import Layout from "../layouts/Layout.astro";
import ParticleCanvas from "../components/ParticleCanvas.astro";
import IcebergSVG from "../components/IcebergSVG.astro";
import TokenViz from "../components/TokenViz.astro";
import AttentionViz from "../components/AttentionViz.astro";
import EmbeddingViz from "../components/EmbeddingViz.astro";
import NeuralNetworkSVG from "../components/NeuralNetworkSVG.astro";
import DiffusionViz from "../components/DiffusionViz.astro";
import RLHFViz from "../components/RLHFViz.astro";
---

<Layout title="The AI Iceberg — Understanding How LLMs Work">
  <ParticleCanvas />

  <!-- Progress bar -->
  <div class="progress-bar" id="progress-bar" aria-hidden="true"></div>

  <!-- ============================================ -->
  <!-- HERO                                         -->
  <!-- ============================================ -->
  <section class="hero" id="hero" aria-label="Introduction">
    <p class="label" id="hero-label">Leon Furze's AI Iceberg</p>
    <h1 id="hero-title">Understanding How<br />AI Really Works</h1>
    <p class="subtitle" id="hero-subtitle">
      Scroll down to dive beneath the surface of AI, exploring the hidden
      layers of large language models — from the applications you see to the
      vast ocean of training data you don't.
    </p>
    <div class="scroll-cue" id="scroll-cue">
      <span>Scroll to explore</span>
      <div class="arrow" aria-hidden="true"></div>
    </div>
  </section>

  <!-- ============================================ -->
  <!-- CHAPTER: THE ICEBERG OVERVIEW                -->
  <!-- ============================================ -->
  <section id="main-content" aria-label="The AI Iceberg overview" tabindex="-1">
    <div class="chapter-divider" id="ch-iceberg">
      <span class="chapter-number">The Big Picture</span>
      <h2 id="ch-iceberg-title">The AI Iceberg</h2>
      <p id="ch-iceberg-desc">
        Most people interact with AI through polished applications like ChatGPT,
        Claude, or Gemini. But like an iceberg, what you see is only a tiny fraction of what's really
        there. The vast majority — the training data, the model architecture, the
        hidden processes — lies beneath the surface.
      </p>
    </div>

    <!-- Sticky iceberg with scrolling text annotations -->
    <div class="scroll-container" id="iceberg-scroll">
      <div class="sticky-graphic" id="iceberg-sticky">
        <IcebergSVG />
      </div>
      <div class="scroll-text">
        <div class="step" data-step="snowman" id="step-snowman">
          <h3>Layer 3: The Application</h3>
          <p>
            Picture a carefully sculpted snowman sitting on top of the iceberg.
            This represents an application like ChatGPT, Claude, or Gemini —
            built on top of a general LLM and fine-tuned specifically for
            conversational tasks.
          </p>
          <p>
            The chatbot layer includes <strong>system messages</strong> (rules
            governing every interaction) and <strong>RLHF</strong>
            (reinforcement learning from human feedback), where human reviewers
            judge outputs as helpful, harmful, correct, or incorrect — shaping
            how the model responds.
          </p>
        </div>

        <div class="step" data-step="llm" id="step-llm">
          <h3>Layer 2: The LLM</h3>
          <p>
            The visible iceberg above the waterline is the Large Language Model
            itself — the result of the training process fuelled by the vast
            dataset beneath. This is where three key technical processes happen.
          </p>
          <p>
            <strong>Tokenization</strong> breaks text into machine-readable
            pieces. <strong>Weighting</strong> assigns probability values to
            connections between tokens. And the
            <strong>transformer architecture</strong> with its
            <strong>attention mechanism</strong> — introduced in 2017 by Google
            researchers — allows the model to consider relationships across
            entire passages of text.
          </p>
          <p>
            LLMs are often called "black boxes" because their internal
            connections are so massively complex that no human or team of humans
            could possibly unravel everything going on inside.
          </p>
        </div>

        <div class="step" data-step="dataset" id="step-dataset">
          <h3>Layer 1: The Dataset</h3>
          <p>
            The bulk of the iceberg — hidden underwater — represents the vast
            dataset on which the LLM is trained. GPT-4 trained on roughly
            <strong>13 trillion tokens</strong> — about 1,600 times the
            population of Earth.
          </p>
          <p>
            Known data sources include Common Crawl, The Pile, Wikipedia,
            GitHub, and social media. Much of the data remains proprietary.
            This layer carries plenty of side effects, including the kind of
            bias and discrimination central to AI ethics discussions.
          </p>
        </div>

        <div class="step" data-step="ocean" id="step-ocean">
          <h3>The Ocean &amp; The Sharks</h3>
          <p>
            The ocean surrounding the iceberg represents the internet at large —
            the vast environment from which the dataset is sourced.
          </p>
          <p>
            And the sharks? They symbolize threats lurking in the data:
            <strong>misinformation</strong>, <strong>bias</strong>,
            <strong>toxic content</strong>, and <strong>data privacy
            issues</strong> that can influence the dataset and, subsequently,
            the behaviour of the LLM.
          </p>
          <blockquote class="pull-quote" id="bender-quote">
            <p>
              &ldquo;A language model is a stochastic parrot &mdash; it
              haphazardly stitches together sequences of linguistic forms
              from its training data, without any reference to meaning.&rdquo;
            </p>
            <cite>&mdash; Emily Bender et al., &ldquo;On the Dangers of Stochastic Parrots&rdquo; (2021)</cite>
          </blockquote>
        </div>
      </div>
    </div>
  </section>

  <!-- ============================================ -->
  <!-- CHAPTER: BENEATH THE SURFACE                 -->
  <!-- ============================================ -->
  <section aria-label="How LLMs work — deep dive">
    <div class="chapter-divider" id="ch-beneath">
      <span class="chapter-number">Beneath the Surface</span>
      <h2>How It Actually Works</h2>
      <p>
        Let's open the black box. The following sections explore the key
        processes that make large language models tick — from breaking text
        into tokens to predicting the next word.
      </p>
    </div>

    <!-- NEXT-TOKEN PREDICTION intro -->
    <div class="full-section" id="next-token-section">
      <span class="label">The Core Insight</span>
      <h2 id="next-token-title">The World's Most Sophisticated Autocomplete</h2>
      <p id="next-token-p1">
        Here's the single most important thing to understand about how LLMs work:
        they build text <strong>one word at a time</strong>, each time predicting
        the most likely next token based on everything that came before.
      </p>
      <p id="next-token-p2">
        Think of the autocomplete on your phone. You type "I'm on my" and it
        suggests "way." An LLM does the same thing — but with vastly more
        context, vastly more data, and vastly more sophistication. It doesn't
        "understand" your message. It predicts what comes next.
      </p>
      <p id="next-token-p3" style="color: var(--text-muted); font-style: italic; font-size: 0.95rem;">
        As AI researcher Gary Marcus puts it, large language models are
        &ldquo;glorified autocomplete&rdquo; &mdash; impressive in their output,
        but fundamentally just predicting the next word.
      </p>
    </div>

    <!-- TOKENIZATION -->
    <div class="chapter-divider" id="ch-tokens">
      <span class="chapter-number">Process 1</span>
      <h2>Tokenization</h2>
      <p>
        Before an LLM can process language, text must be broken into small
        pieces called tokens — like Scrabble tiles the model can work with.
      </p>
    </div>

    <p class="viz-instruction">Scroll to see how text is broken into tokens</p>
    <TokenViz />

    <!-- EMBEDDINGS -->
    <div class="chapter-divider" id="ch-embeddings">
      <span class="chapter-number">Process 2</span>
      <h2>Embeddings</h2>
      <p>
        Each token becomes a numerical vector — essentially GPS coordinates in
        "meaning space," where similar concepts naturally cluster together.
        These positions are learned during training, not hand-coded.
      </p>
    </div>

    <p class="viz-instruction">Scroll to explore meaning space</p>
    <EmbeddingViz />

    <!-- ATTENTION -->
    <div class="chapter-divider" id="ch-attention">
      <span class="chapter-number">Process 3</span>
      <h2>Attention</h2>
      <p>
        The breakthrough that made modern AI possible. The attention mechanism
        lets each word look at every other word to understand context — resolving
        ambiguity in ways previous architectures couldn't.
      </p>
    </div>

    <p class="viz-instruction">Scroll to see attention in action</p>
    <AttentionViz />

    <!-- NEURAL NETWORK / TRANSFORMER -->
    <div class="chapter-divider" id="ch-transformer">
      <span class="chapter-number">Putting It Together</span>
      <h2>The Transformer Architecture</h2>
      <p>
        Tokenization, embeddings, and attention combine inside a
        transformer — the architecture introduced in Google's landmark 2017
        paper "Attention Is All You Need" that powers every modern LLM.
      </p>
    </div>

    <p class="viz-instruction">Scroll to open the black box</p>
    <NeuralNetworkSVG />

    <!-- RLHF -->
    <div class="chapter-divider" id="ch-rlhf">
      <span class="chapter-number">The Final Step</span>
      <h2>RLHF: Teaching the Model Manners</h2>
      <p>
        A raw LLM is powerful but unruly — it might generate toxic content,
        confidently state falsehoods, or ignore your actual question. That's
        where <strong>RLHF</strong> comes in.
      </p>
    </div>

    <div class="full-section" id="rlhf-section">
      <h3 id="rlhf-title">Reinforcement Learning from Human Feedback</h3>
      <p id="rlhf-p1">
        After the base model is trained on trillions of tokens, human reviewers
        step in. They're shown pairs of model outputs and asked: <em>which
        response is more helpful, more accurate, less harmful?</em> These
        preferences are used to train a <strong>reward model</strong> — a
        separate system that learns to score outputs the way humans would.
      </p>
      <p id="rlhf-p2">
        The LLM is then fine-tuned using reinforcement learning to maximise
        that reward score. Over many iterations, the model learns to produce
        responses that are helpful, honest, and safe — not because it
        understands these concepts, but because it's been optimised to match
        human preferences. This is what turns a raw text predictor into a
        usable assistant like ChatGPT or Claude.
      </p>
      <p id="rlhf-p3" style="font-size: 0.95rem; color: var(--text-muted); font-style: italic;">
        RLHF is the "snowman sculptor" — the process that shapes the raw
        iceberg into the polished application sitting on top.
      </p>
      <p id="rlhf-p4">
        But there&rsquo;s a hidden cost. The humans doing this work &mdash; many
        employed through outsourcing firms in Kenya, the Philippines, and other
        countries &mdash; are often paid less than $2 per hour to review and classify
        content, including violent, sexual, and deeply disturbing material. A 2023
        <em>Time</em> investigation revealed that workers labelling data for ChatGPT
        described the work as &ldquo;torture.&rdquo; This is the invisible human
        labour that makes AI &ldquo;alignment&rdquo; possible.
      </p>
      <blockquote class="pull-quote" id="crawford-quote">
        <p>
          &ldquo;Artificial intelligence is neither artificial nor intelligent.
          It is both embodied and material, made from natural resources, fuel,
          human labor, infrastructures, logistics, histories, and
          classifications.&rdquo;
        </p>
        <cite>&mdash; Kate Crawford, <em>Atlas of AI</em> (2021)</cite>
      </blockquote>
    </div>

    <RLHFViz />
  </section>

  <!-- ============================================ -->
  <!-- CHAPTER: BEYOND TEXT                         -->
  <!-- ============================================ -->
  <section aria-label="Beyond text — image generation">
    <div class="chapter-divider" id="ch-diffusion">
      <span class="chapter-number">Beyond Text</span>
      <h2>How AI Generates Images</h2>
      <p>
        Image generators like DALL-E, Stable Diffusion, and Midjourney use a
        different technique called diffusion. Imagine ink diffusing in a glass
        of water until it's uniformly mixed — then learning to run the process
        in reverse, starting from pure noise and gradually "un-mixing" it into
        a coherent image, guided by a text prompt.
      </p>
    </div>

    <p class="viz-instruction">Scroll to watch noise become an image</p>
    <DiffusionViz />
  </section>

  <!-- ============================================ -->
  <!-- CHAPTER: THE BIGGER PICTURE                  -->
  <!-- ============================================ -->
  <section class="full-section" id="misconceptions-section" aria-label="Common misconceptions">
    <span class="label">A Critical Reminder</span>
    <h2 id="misconceptions-title">Chatbots Don&rsquo;t Make Sense, They Make Words</h2>
    <p id="misconceptions-p1">
      The terminology we use for AI &mdash; &ldquo;learns,&rdquo; &ldquo;thinks,&rdquo;
      &ldquo;understands&rdquo; &mdash; is what researcher Melanie Mitchell calls
      <strong>wishful mnemonics</strong>. These words describe what the system
      <em>appears</em> to do, not what it actually does. An LLM is a sophisticated
      statistical prediction engine, not a mind.
    </p>
    <p id="misconceptions-p2">
      That&rsquo;s why Leon Furze chose the iceberg metaphor: &ldquo;I&rsquo;m
      deliberately avoiding any kind of analogy that represents the AI as magical,
      mythical, human, or godlike &mdash; we&rsquo;ve seen enough of them.&rdquo;
      The iceberg emphasises hidden infrastructure, not hidden intelligence.
    </p>
    <p id="misconceptions-p3">
      What about &ldquo;reasoning&rdquo; models like OpenAI&rsquo;s o1 or DeepSeek-R1?
      These models are trained to generate a <strong>chain of thought</strong> &mdash;
      working through a problem step by step before answering. But the mechanism is
      identical: they&rsquo;re still predicting the next token. The &ldquo;reasoning&rdquo;
      is just more tokens &mdash; the model has learned that writing out intermediate
      steps leads to better final answers. It&rsquo;s autocomplete that&rsquo;s been
      taught to show its working.
    </p>
  </section>

  <!-- ============================================ -->
  <!-- CTA: BOOK / MAILING LIST                     -->
  <!-- ============================================ -->
  <section class="cta-section" id="cta-section" aria-label="Subscribe for updates">
    <div class="cta-inner">
      <span class="label">Coming Q4 2026</span>
      <h2 class="cta-heading" id="cta-heading">Practical AI Strategies 2</h2>
      <p class="cta-subtitle">The Critical Guide to GenAI in Education</p>
      <p class="cta-body" id="cta-body">
        Stay ahead of the curve. Subscribe for articles, resources, and updates
        on understanding generative AI &mdash; delivered straight to your inbox.
      </p>
      <script async data-uid="bca563faa0" src="https://leon-furze.kit.com/bca563faa0/index.js"></script>
    </div>
  </section>

  <!-- ============================================ -->
  <!-- FOOTER                                       -->
  <!-- ============================================ -->
  <footer class="footer">
    <p>
      Based on the <strong>AI Iceberg</strong> model by
      <a href="https://leonfurze.com/2023/05/18/the-ai-iceberg-understanding-chatgpt/" target="_blank" rel="noopener noreferrer">Leon Furze</a>,
      from <em>Practical AI Strategies</em> (Amba Press, 2024).
    </p>
    <p>
      Iceberg image freely usable in presentations with credit to
      <a href="https://leonfurze.com" target="_blank" rel="noopener noreferrer">leonfurze.com</a>.
    </p>
  </footer>
</Layout>

<script>
  /**
   * Main page orchestration — GSAP ScrollTrigger setup for all sections.
   * This script runs after Layout.astro registers gsap + ScrollTrigger globally.
   */
  function initScrollAnimations() {
    const gsap = (window as any).gsap;
    const ScrollTrigger = (window as any).ScrollTrigger;

    if (!gsap || !ScrollTrigger) return;

    const prefersReduced = window.matchMedia("(prefers-reduced-motion: reduce)").matches;

    // --- Progress bar ---
    gsap.to("#progress-bar", {
      width: "100%",
      ease: "none",
      scrollTrigger: {
        trigger: "body",
        start: "top top",
        end: "bottom bottom",
        scrub: 0.3,
      },
    });

    // --- Hero animations ---
    if (!prefersReduced) {
      gsap.from("#hero-label", { opacity: 0, y: 20, duration: 0.8, delay: 0.2 });
      gsap.from("#hero-title", { opacity: 0, y: 30, duration: 1, delay: 0.4 });
      gsap.from("#hero-subtitle", { opacity: 0, y: 20, duration: 0.8, delay: 0.7 });
      gsap.from("#scroll-cue", { opacity: 0, duration: 0.8, delay: 1.2 });

      // Fade out hero on scroll
      gsap.to("#hero", {
        opacity: 0,
        y: -50,
        scrollTrigger: {
          trigger: "#hero",
          start: "center center",
          end: "bottom top",
          scrub: true,
        },
      });
    }

    // --- Chapter dividers fade in ---
    gsap.utils.toArray(".chapter-divider").forEach((el: any) => {
      if (prefersReduced) return;
      gsap.from(el.querySelector(".chapter-number"), {
        opacity: 0, y: 15, duration: 0.5,
        scrollTrigger: { trigger: el, start: "top 80%", toggleActions: "play none none reverse" },
      });
      gsap.from(el.querySelector("h2"), {
        opacity: 0, y: 20, duration: 0.6,
        scrollTrigger: { trigger: el, start: "top 78%", toggleActions: "play none none reverse" },
      });
      const desc = el.querySelector("p");
      if (desc) {
        gsap.from(desc, {
          opacity: 0, y: 15, duration: 0.6,
          scrollTrigger: { trigger: el, start: "top 75%", toggleActions: "play none none reverse" },
        });
      }
    });

    // --- Next-token prediction section ---
    if (!prefersReduced) {
      ["#next-token-title", "#next-token-p1", "#next-token-p2", "#next-token-p3"].forEach((sel, i) => {
        gsap.from(sel, {
          opacity: 0, y: 20, duration: 0.6,
          scrollTrigger: {
            trigger: "#next-token-section",
            start: `top ${80 - i * 5}%`,
            toggleActions: "play none none reverse",
          },
        });
      });
    }

    // --- Iceberg scroll section: sticky graphic + step triggers ---
    const icebergSteps = gsap.utils.toArray("#iceberg-scroll .step");

    icebergSteps.forEach((step: any) => {
      ScrollTrigger.create({
        trigger: step,
        start: "top 60%",
        end: "bottom 40%",
        onEnter: () => activateIcebergStep(step.dataset.step, step),
        onEnterBack: () => activateIcebergStep(step.dataset.step, step),
        onLeave: () => step.classList.remove("is-active"),
        onLeaveBack: () => step.classList.remove("is-active"),
      });
    });

    function activateIcebergStep(stepName: string, stepEl: Element) {
      // Deactivate all steps, activate current
      icebergSteps.forEach((s: any) => s.classList.remove("is-active"));
      stepEl.classList.add("is-active");

      // Animate iceberg labels based on step
      const duration = prefersReduced ? 0 : 0.5;
      const ease = "power2.out";

      // Reset all labels
      gsap.to("#label-applications, #label-llm, #label-dataset, #label-ocean, #shark-labels", {
        opacity: 0, duration: duration * 0.5, ease,
      });

      switch (stepName) {
        case "snowman":
          gsap.to("#label-applications", { opacity: 1, duration, ease });
          break;
        case "llm":
          gsap.to("#label-llm", { opacity: 1, duration, ease });
          break;
        case "dataset":
          gsap.to("#label-dataset", { opacity: 1, duration, ease });
          break;
        case "ocean":
          gsap.to("#label-ocean", { opacity: 1, duration, ease });
          gsap.to("#shark-labels", { opacity: 1, duration, ease, delay: 0.2 });
          break;
      }
    }

    // --- RLHF section ---
    if (!prefersReduced) {
      ["#rlhf-title", "#rlhf-p1", "#rlhf-p2", "#rlhf-p3", "#rlhf-p4", "#crawford-quote"].forEach((sel, i) => {
        gsap.from(sel, {
          opacity: 0, y: 20, duration: 0.6,
          scrollTrigger: {
            trigger: sel,
            start: "top 82%",
            toggleActions: "play none none reverse",
          },
        });
      });
    }

    // --- Misconceptions section ---
    if (!prefersReduced) {
      ["#misconceptions-title", "#misconceptions-p1", "#misconceptions-p2", "#misconceptions-p3"].forEach((sel, i) => {
        gsap.from(sel, {
          opacity: 0, y: 20, duration: 0.6,
          scrollTrigger: {
            trigger: "#misconceptions-section",
            start: `top ${80 - i * 5}%`,
            toggleActions: "play none none reverse",
          },
        });
      });
    }

    // --- Full section label animations ---
    gsap.utils.toArray(".full-section .label").forEach((label: any) => {
      if (prefersReduced) return;
      gsap.from(label, {
        opacity: 0, y: 10, duration: 0.5,
        scrollTrigger: {
          trigger: label,
          start: "top 85%",
          toggleActions: "play none none reverse",
        },
      });
    });

    // --- Instruction panel fade-ins ---
    gsap.utils.toArray(".viz-instruction").forEach((el: any) => {
      if (prefersReduced) return;
      gsap.from(el, {
        opacity: 0, y: 10, duration: 0.5,
        scrollTrigger: {
          trigger: el,
          start: "top 88%",
          toggleActions: "play none none reverse",
        },
      });
    });

    // --- Bender pull quote ---
    if (!prefersReduced) {
      gsap.from("#bender-quote", {
        opacity: 0, y: 15, duration: 0.6,
        scrollTrigger: {
          trigger: "#bender-quote",
          start: "top 80%",
          toggleActions: "play none none reverse",
        },
      });
    }

    // --- CTA section ---
    if (!prefersReduced) {
      gsap.from("#cta-heading", {
        opacity: 0, y: 20, duration: 0.6,
        scrollTrigger: {
          trigger: "#cta-section",
          start: "top 80%",
          toggleActions: "play none none reverse",
        },
      });
      gsap.from("#cta-body", {
        opacity: 0, y: 15, duration: 0.6,
        scrollTrigger: {
          trigger: "#cta-section",
          start: "top 75%",
          toggleActions: "play none none reverse",
        },
      });
    }

    // --- Footer fade-in ---
    if (!prefersReduced) {
      gsap.from(".footer", {
        opacity: 0,
        y: 30,
        duration: 0.8,
        ease: "power2.out",
        scrollTrigger: {
          trigger: ".footer",
          start: "top 90%",
          toggleActions: "play none none reverse",
        },
      });
    }
  }

  // Initialize when DOM is ready
  if (document.readyState === "loading") {
    document.addEventListener("DOMContentLoaded", () => {
      requestAnimationFrame(initScrollAnimations);
    });
  } else {
    requestAnimationFrame(initScrollAnimations);
  }
</script>

<style>
  /* Page-specific styles that supplement global.css */

  /* ── Section gradient blending (Reuters 0%–90% pattern) ── */

  /* Iceberg overview — light teal tint */
  #main-content {
    background: linear-gradient(
      180deg,
      var(--bg-primary) 0% 85%,
      var(--bg-secondary)
    );
  }

  /* Deep dive chapter */
  [aria-label="How LLMs work — deep dive"] {
    background: linear-gradient(
      180deg,
      var(--bg-secondary) 0%,
      var(--bg-primary) 10% 90%,
      var(--bg-secondary)
    );
  }

  /* Beyond text section */
  [aria-label="Beyond text — image generation"] {
    background: linear-gradient(
      180deg,
      var(--bg-secondary) 0%,
      var(--bg-primary) 10% 90%,
      var(--bg-primary)
    );
  }

  /* Misconceptions closing section */
  #misconceptions-section {
    min-height: auto;
    padding-bottom: var(--space-lg);
    background: linear-gradient(
      180deg,
      var(--bg-primary) 0%,
      var(--bg-secondary) 50%,
      var(--bg-primary) 100%
    );
  }

  #misconceptions-section h2 {
    background: linear-gradient(
      135deg,
      var(--text-primary) 0%,
      var(--accent-cyan) 60%,
      var(--accent-blue) 100%
    );
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-clip: text;
  }

  #next-token-section strong {
    color: var(--accent-cyan);
  }

  /* Next token section — subtle emphasis background */
  #next-token-section {
    background: radial-gradient(
      ellipse at center,
      rgba(8, 145, 178, 0.04) 0%,
      transparent 70%
    );
  }

  /* Ensure iceberg scroll container has enough height for scrolling */
  #iceberg-scroll {
    min-height: 300vh;
  }

  #iceberg-scroll .scroll-text {
    padding-top: 20vh;
    padding-bottom: 20vh;
  }

  /* ── Pull quote (Bender etc.) ── */
  .pull-quote {
    margin: 1.5rem 0 0;
    padding: 1.25rem 1.5rem;
    border-left: 3px solid var(--accent-cyan);
    background: rgba(8, 145, 178, 0.04);
    border-radius: 0 8px 8px 0;
  }

  .pull-quote p {
    font-size: 0.95rem;
    font-style: italic;
    line-height: 1.7;
    color: var(--text-secondary);
    margin: 0 0 0.5rem;
  }

  .pull-quote cite {
    font-size: 0.8rem;
    font-style: normal;
    color: var(--text-muted);
    display: block;
  }

  /* ── CTA section ── */
  .cta-section {
    text-align: center;
    padding: var(--space-xl) var(--space-lg);
    background: linear-gradient(
      180deg,
      var(--bg-primary) 0%,
      rgba(8, 145, 178, 0.06) 50%,
      var(--bg-primary) 100%
    );
  }

  .cta-inner {
    max-width: 580px;
    margin: 0 auto;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 0.75rem;
  }

  .cta-heading {
    font-family: var(--font-display);
    font-size: clamp(1.6rem, 4vw, 2.2rem);
    font-weight: 700;
    color: var(--text-primary);
    margin: 0;
    letter-spacing: -0.02em;
  }

  .cta-subtitle {
    font-family: var(--font-sans);
    font-size: clamp(0.95rem, 2vw, 1.1rem);
    color: var(--accent-cyan);
    font-weight: 500;
    margin: 0;
  }

  .cta-body {
    font-size: 0.95rem;
    color: var(--text-secondary);
    line-height: 1.7;
    margin: 0.5rem 0 0.5rem;
  }


  /* ── Instruction panels before visualizations ── */
  .viz-instruction {
    text-align: center;
    padding: var(--space-md) var(--space-lg);
    margin: 0 auto var(--space-lg);
    max-width: 28rem;
    font-size: var(--font-size-sm, 0.875rem);
    color: var(--text-muted);
    letter-spacing: 0.02em;
    opacity: 0.7;
    border-top: 1px solid rgba(8, 145, 178, 0.1);
    border-bottom: 1px solid rgba(8, 145, 178, 0.1);
  }
</style>
